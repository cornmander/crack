# Copyright 2010 Google Inc.
# Implements some basic annotations that no one should be without.  Included
# are:
# @define name(arg, ...) { contents }
#   defines a macro with the specified arguments (you can then use the macro 
#   as @name(args...))
# @interface I { ... }
#   Defines a class as an interface (similar to crack.lang.MixIn, only you can 
#   implement multiple of them)
# class A : Object @implements I, J { ... }
#   Makes a class implement the list of interfaces that follows them (this 
#   mainly entails doing normal class derivation and implementing the 
#   'get<interface>Object()' method.

import crack.runtime free;
import crack.lang die, CString, IndexError, InvalidArgumentError, 
    AssertionError;
import crack.io cout, FStr, StringFormatter, StringWriter, Formatter, Reader, 
    Writer;
import crack.compiler CrackContext, Token, Location, TOK_COMMA, TOK_STRING, 
    TOK_POPERRCTX;
import crack.cont.array Array;
import crack.cont.treemap TreeMap;
import crack.exp.serial SerialReader, SerialWriter;

const NOT_FOUND := 0xFFFFFFFF;

## Serial writer with some additional facilities to simplify macro 
## serialization.
class MacroSerializer : SerialWriter {
    TreeMap[String, uint] sourceNames = {};
    uint lastIdx;

    oper init(Writer dst) : SerialWriter(dst) {}
    
    void writeSrcName(String name) {
        idx := sourceNames.get(name, NOT_FOUND);
        if (idx != NOT_FOUND) {
            write(idx);
        } else {
            # new name, write the index and the 
            sourceNames[name] = lastIdx;
            write(lastIdx++);
            write(name);
        }
    }

    void writeLocation(Location loc) {
        writeSrcName(String(loc.getName()));
        write(uint(loc.getLineNumber()));
    }
}

## Serial reader with some additional facilities to simplify macro 
## deserialization.
class MacroDeserializer : SerialReader {
    CrackContext ctx;
    Array[String] sourceNames = {4};
    
    oper init(CrackContext ctx, Reader src) : SerialReader(src), ctx = ctx {}
    
    String readSrcName() {
        # read the index
        idx := readUInt();
        count := sourceNames.count();
        if (idx > count) {
            throw IndexError(FStr() `Invalid source name index: $idx\n`);
        } else if (idx == count) {
            name := readString();
            sourceNames.append(name);
            return name;
        } else {
            return sourceNames[idx];
        }
    }

    Location readLocation() {
        return ctx.getLocation(readSrcName().buffer, int(readUInt()));
    }
}

class Node;
class NodeIter;

@abstract class NodeList {
    @abstract void pushHead(Node node);
    @abstract void append(Node node);
    @abstract Node popHead();
    @abstract void writeTo(MacroSerializer dst);
    @abstract NodeIter iter();
    @abstract Node getLast();
    @abstract Node getFirst();
}

@abstract class Node {
    Node next;
    
    void expand(CrackContext ctx, Array[NodeList] args) {}
    String toString(Array[NodeList] args) {return null;}
    @abstract Location getLocation();
    @abstract void writeTo(MacroSerializer dst);
}

class NodeIter {
    Node node;
    oper init(Node node) : node = node {}
    void next() { node = node.next; }
    bool isTrue() { return node; }
    Node elem() { return node; }
}

Node _readNode(MacroDeserializer src);

## A list of tokens.  These are typically stored in reverse order of the 
## actual order of the tokens so that they can be easily "put back" into the 
## token stream (after putBack() they will be in the correct order once again)
class NodeListImpl : NodeList {
    Node first, last;
    
    oper init() {}
    
    void pushHead(Node node) {
        if (first) {
            node.next = first;
            first = node;
        } else {
            first = last = node;
        }
    }    
    
    void append(Node node) {
        if (last) {
            last.next = node;
            last = node;
        } else {
            first = last = node;
        }
    }
    
    Node popHead() {
        if (first) {
            if (last is first)
                last = null;
            result := first;
            first = first.next;
            return result;
        } else {
            return null;
        }
    }

    oper init(MacroDeserializer src) {
        # get the number of nodes in the list
        count := src.readUInt();
        while (count--) {
            append(_readNode(src));
            #cout `remaining = $count\n`;
        }
    }
    
    void writeTo(MacroSerializer dst) {
        
        # count the nodes and write the count
        node := first;
        uint count;
        while (node) {
            ++count;
            node = node.next;
        }
        #cout `writing count $count\n`;
        dst.write(count);
   
        # write all of the nodes
        node = first;
        while (node) {
            node.writeTo(dst);
            node = node.next;
        }
    }

    void __write(Writer out, Node node) {
        if (node.next)
            __write(out, node.next);
        node.writeTo(out);
    }
    
    void writeTo(Writer out) {
        __write(out, first);
    }

    NodeIter iter() { return NodeIter(first); }

    ## Node lists are true if they have any contents.
    bool isTrue() { return first; }
    
    Node getLast() { return last; }
    Node getFirst() { return first; }
}

class Tok : Node {
    Token tok;

    oper init(Token tok) : tok = tok {}

    oper init() {}

    void expand(CrackContext ctx, Array[NodeList] args) {
        ctx.putBack(tok);
    }
    
    String toString(Array[NodeList] args) {
        if (tok.isString())
            return String(tok.getText()).getRepr();
        else
            return String(tok.getText());
    }
    
    Location getLocation() {
        return tok.getLocation();
    }
    
    void writeTo(Writer out) {
        if (tok.isString()) {
            out.write(' ');
            out.write(String(tok.getText()).getRepr());
        } else {
            out.write(' ');
            out.write(StaticString(tok.getText()));
        }
    }

    void writeTo(MacroSerializer dst) {
        
        # my node type
        dst.write(0);
        
        # the token
        dst.write(uint(tok.getType()));
        dst.write(String(tok.getText()));
        
        dst.writeLocation(tok.getLocation());
    }
    
    oper init(MacroDeserializer src) {
        type := int(src.readUInt());
        text := src.readString();
        locName := src.readSrcName();
        locLineNum := src.readUInt();
    
        #cout `read token: $type, $text, $locName, $locLineNum\n`;    
        tok = Token(type, text.buffer, 
                    src.ctx.getLocation(locName.buffer, int(locLineNum))
                    );
    }
}

class Arg : Node {
    uint argIndex;
    Location loc;
    
    oper init(Location loc, uint argIndex) : 
        loc = loc,
        argIndex = argIndex {
    }
    
    oper init() {}

    void expand(CrackContext ctx, Array[NodeList] args) {
        for (node :in NodeList.cast(args[argIndex]))
            node.expand(ctx, args);
    }
    
    String toString(Array[NodeList] args) {
        StringFormatter sf = {};
        argVal := NodeList.cast(args[argIndex]);
        
        # do the last node so we can add a whitespace separator for every 
        # subsequent node.
        if (last := argVal.getLast())
            sf.format(last.toString(args));
        
        # do the rest of the nodes
        void reverseNodeList(Array[NodeList] args1, StringFormatter out, 
                             Node node
                             ) {
            
            # stop recursing before the last node
            if (node.next) {
                reverseNodeList(args1, out, node.next);
                out ` $(node.toString(args1))`;
            }
        }

        reverseNodeList(args, sf, argVal.getFirst());
        return sf.createCString();
    }
    
    void writeTo(Writer out) { Formatter(out) `arg: $argIndex\n`; }
    Location getLocation() { return loc; }
    
    oper init(MacroDeserializer src) {
        argIndex = src.readUInt();
        loc = src.readLocation();
        #cout `read arg $argIndex\n`;
    }
    
    void writeTo(MacroSerializer dst) {
        
        # write my type id
        dst.write(1);
        
        # write the arg id and location fields
        dst.write(argIndex);
        dst.writeLocation(loc);
    }
}

## Concat nodes concatenate a set of tokens into a single token.  The type and 
## location come from the first non-argument token.
class Concat : Node {
    NodeList list;
    int type;
    Location loc;

    oper init(NodeList list, Location loc) : 
        loc = loc,
        list = list {
    }
    
    oper init() {}

    void expand(CrackContext ctx, Array[NodeList] args) {
        StringFormatter concat = {};
        for (item :in list)
            concat.format(item.toString(args));
        concat.format(' \0');
        
        s := concat.createString();
        ctx.inject(@FILE.buffer, @LINE, s.buffer);
    }
    
    String toString(Array[NodeList] args) {
        die('Concat.toString() called.');
        return null;
    }
    
    Location getLocation() {
        return loc;
    }

    oper init(MacroDeserializer src) {
        list = NodeListImpl(src);
        type = int(src.readUInt());
        loc = src.readLocation();
    }
    
    void writeTo(MacroSerializer dst) {
        dst.write(2);
        
        list.writeTo(dst);
        dst.write(uint(type));
        dst.writeLocation(loc);
    }
}

class Stringify : Node {
    Node node;
    
    oper init(Node node) : node = node {}
    
    void expand(CrackContext ctx, Array[NodeList] args) {
        ctx.putBack(Token(TOK_STRING, node.toString(args).buffer, 
                          node.getLocation()
                          )
                    );
    }
    
    String toString(Array[NodeList] args) {
        die('Stringify.toString called.');
        return null;
    }
    
    Location getLocation() {
        return node.getLocation();
    }
    
    oper init(MacroDeserializer src) {
        node = _readNode(src);
    }
    
    void writeTo(MacroSerializer dst) {
        
        # write my type id.
        dst.write(3);
        
        node.writeTo(dst);
    }
}

Node _readNode(MacroDeserializer src) {
    type := src.readUInt();
    Node node;
    if (type == 0)
        node = Tok(src);
    else if (type == 1)
        node = Arg(src);
    else if (type == 2)
        node = Concat(src);
    else if (type == 3)
        node = Stringify(src);
    else
        throw AssertionError(FStr() `bogus node $type\n`);
    
    return node;
}

## Parse macro arguments, returns them as an array of NodeList objects.
Array[NodeList] parseArgs(CrackContext ctx, uint argCount) {
    # extract the arguments from the following tokens
    tok := ctx.getToken();
    if (!tok.isLParen())
        ctx.error(tok, 'left paren expected in macro expansion'.buffer);
    
    uint nesting = 1;
    argTokList := NodeListImpl();
    Array[NodeList] args = {argCount};
    while (true) {
        tok = ctx.getToken();
        if (nesting == 1 && tok.isComma()) {
            args.append(argTokList);
            argTokList = NodeListImpl();
        } else {
            if (tok.isLParen()) {
                ++nesting;
            } else if (tok.isRParen()) {
                if (!--nesting)
                    break;
            }

            argTokList.pushHead(Tok(tok));
        }
    }
    
    # if we got a non-empty element left over, add it to the list.
    if (argTokList.getFirst())
        args.append(argTokList);
    
    # verify that the number of arguments provided was correct
    if (args.count() != argCount) {
        fmt := StringFormatter();
        fmt `Incorrect number of arguments for macro: expected \
$(argCount), got $(args.count())\0`;
        ctx.error(tok, fmt.createString().buffer);
    }

    return args;
}

class Macro : NodeListImpl {
    String name;
    uint argCount;

    oper init() {}
    oper init(MacroDeserializer src) : NodeListImpl(src) {
        name = src.readString();
        argCount = src.readUInt();
    }
    
    void writeTo(MacroSerializer dst) {
        NodeListImpl.writeTo(dst);
        dst.write(name);
        dst.write(argCount);
    }
    
    void expand(CrackContext ctx) {
        # hold onto the last location
        loc := ctx.getLocation();
        
        # parse the args.
        args := parseArgs(ctx, argCount);
        
        # install the "pop error context" token so that our error context only 
        # shows up for the expansion of the macro.
        ctx.putBack(Token(TOK_POPERRCTX, '[pop error context]'.buffer,
                          loc
                          )
                    );

        # expand the macro
        Node node = first;
        while (node) {
            node.expand(ctx, args);
            node = node.next;
        }
        
        # push an error context
        StringFormatter fmt = {};
        fmt `expanded from macro at $(loc.getName()):$(loc.getLineNumber())`;
        ctx.pushErrorContext(fmt.createCString().buffer);
    }    
}

## Annotation to expand a macro.  This expects a Macro instance as user data.
void expand(CrackContext ctx) {
    mac := Macro.unsafeCast(ctx.getUserData());
    mac.expand(ctx);
}

# macro parser states
ST_NONE := 0;
ST_ESC := 1;   # got a dollar-sign escape
ST_CONCAT := 2;  # got a double-dollar-sign concatenation operator
ST_ISTR := 3; # MUST BE THE HIGHEST VALUE STATE.  Values greater than this 
              # indicate levels of nested parens in an i-string.

void define(CrackContext ctx) {
    Macro mac = {};
    TreeMap[String, uint] args = {};
    uint index;
    tok := ctx.getToken();
    
    if (!tok.isIdent())
        ctx.error(tok, 'Macro name expected after define.'.buffer);
    mac.name = String(tok.getText());
    
    # parse the '(' that begins the argument list
    tok = ctx.getToken();
    if (!tok.isLParen())
        ctx.error(tok, 'Left paren expected after macro definition'.buffer);
    
    # read all of the arguments
    while (true) {
        tok = ctx.getToken();
        if (tok.isRParen())
            break;
        
        if (!tok.isIdent())
            ctx.error(tok, 'identifier expected'.buffer);

        args[String(tok.getText())] = index++;
        
        tok = ctx.getToken();
        if (tok.isRParen())
            break;
        else if (!tok.isComma())
            ctx.error('comma or end paren expected in macro def'.buffer);
    }
    mac.argCount = index;
    
    # read the body of the macro
    tok = ctx.getToken();
    if (!tok.isLCurly())
        ctx.error('Expected left bracket'.buffer);

    # read everything until the end bracket
    uint bracketCount = 1;
    int state = ST_NONE;
    NodeListImpl lastConcat = {};  # last concatenation sequence.
    Node node;  # the last node
    while (true) {
        tok = ctx.getToken();
        uint argIndex;
        
        if (tok.isEnd()) {
            ctx.error(
                'End of file before the end of a macro definition'.buffer
            );
        } else if (state >= ST_ISTR) {
            # keep track of the parens.
            if (tok.isLParen())
                ++state;
            else if (tok.isRParen() && --state == ST_ISTR) 
                # we have to tell the tokenizer to continue parsing the 
                # i-string.
                ctx.continueIString();
            else if (tok.isIstrBegin())
                ctx.error('Nested interpolation strings may not be used '
                           'in macros.'.buffer
                          );
            else if (tok.isDollar())
                ctx.error('Nested concatenations and stringifications may not '
                           'be used in a macro.'.buffer
                          );
            else if (tok.isIstrEnd())
                state = ST_NONE;
            else if (state == ST_ISTR && tok.isIdent())
                # an identifier takes us immediately back into the i-string
                ctx.continueIString();
        } else if (tok.isIstrBegin()) {
            if (state != ST_NONE)
                ctx.error('An interpolation string may not be used with '
                           'stringification or concatenation.'.buffer
                          );
            state = ST_ISTR;
        # check for brackets, increment or decrement the bracket count.
        } else if (tok.isRCurly()) {
            if (!--bracketCount)
                break;
        } else if (tok.isLCurly()) {
            ++bracketCount;
        } else if (tok.isDollar()) {
            if (state == ST_NONE) {
                state = ST_ESC;
            } else if (state == ST_ESC) {
                if (!node)
                    ctx.error('The macro may not begin with a concatenation '
                               'operator'.buffer
                              );
                else if (node.isa(Tok) && 
                         Tok.cast(node).tok.isIstrEnd()
                         )
                    ctx.error('An interpolation string may not be used with '
                               'stringification or concatenation'.buffer
                              );
                
                # if we're starting off a new concatenation sequence, add the 
                # last node and store the sequence as a new node in the macro.
                if (!lastConcat) {
                    lastConcat.append(node);
                    mac.popHead();
                    mac.pushHead(Concat(lastConcat, tok.getLocation()));
                }

                state = ST_CONCAT;
            } else {
                ctx.error('One two many dollar signs\n'.buffer);
            }
            continue;
        }

        # replace arguments with indices
        if (tok.isIdent() &&
            (argIndex = args.get(String(tok.getText()), NOT_FOUND)) != 
             NOT_FOUND
            )
            node = Arg(tok.getLocation(), argIndex);
        else
            node = Tok(tok);

        # handle special states
        if (state == ST_CONCAT) {
            
            # concatenation state - add the new node to the concatenation 
            # sequence.
            lastConcat.append(node);
            state = ST_NONE;
        } else if (state == ST_ESC) {
            
            # stringify state - add a stringify node.
            mac.pushHead(Stringify(node));
            state = ST_NONE;
        } else {
            mac.pushHead(node);
            
            # reset any last concatenation sequence that we've accumulated
            if (lastConcat)
                lastConcat = NodeListImpl();
        }
    }
    
    # store a new annotation for expanding the macro
    ctx.storeAnnotation(mac.name.buffer, expand, mac);
    mac.oper bind();
}

void export(CrackContext ctx) {
    
    # get the next token, make sure it's an annotation.
    tok := ctx.getToken();
    if (!tok.isIdent())
        ctx.error(tok, 'Identifier expected'.buffer);
    name := CString(tok.getText(), false);
    ann := ctx.getAnnotation(name.buffer);
    Macro mac;
    if (ann is null) {
        StringFormatter fmt = {};
        fmt `$name is not an annotation.\0`;
        ctx.error(tok, fmt.createString().buffer);
    } else {
        mac = Macro.unsafeCast(ann.getUserData());
    }
    
    # serialize the macro into a string
    flatMac := StringWriter();
    mac.writeTo(MacroSerializer(flatMac));
    
    StringFormatter code = {};
    f := @FILE; l := @LINE; code `
    
        void $name(CrackContext ctx) {
            userData := 
                ctx.getUserData();
            Macro mac;
            if (userData is null) {
                StringReader reader = { $(flatMac.createString().getRepr()) };
                mac = Macro(MacroDeserializer(ctx, reader));
                ctx.storeAnnotation($(name.getRepr()).buffer, $name,
                                    mac
                                    );
                mac.oper bind();
            } else {
                mac = Macro.unsafeCast(userData);
            }
            
            mac.expand(ctx);
        }
    \n\0`;
    ctx.inject(f.buffer, l, code.createString().buffer);
}

## Call this annotation at the top of your file if you want to export macros.  
## It will import everything you need.
void exporter(CrackContext ctx) {
    StringFormatter f = {};
    f `import crack.ann Macro, MacroDeserializer, Node, NodeList, Tok, Arg, 
        Stringify, Concat;
       import crack.compiler CrackContext, Token, TOK_STRING;
       import crack.io StringReader;`;
    ctx.inject(@FILE.buffer, @LINE, 
               f.createCString().buffer);
}

void readIStr(CrackContext ctx, NodeList nodes) {
    depth := 0;
    
    while (true) {
        tok := ctx.getToken();
        nodes.pushHead(Tok(tok));
        if (tok.isLParen())
            ++depth;
        else if (tok.isRParen() && !--depth)
            ctx.continueIString();
        else if (tok.isIdent() && !depth)
            ctx.continueIString();
        else if (tok.isIstrEnd())
            return;
    }
}

NodeList readBlock(CrackContext ctx) {
    NodeListImpl result = {};

    # get the opening bracket.
    tok := ctx.getToken();
    if (!tok.isLCurly())
        ctx.error(tok, 'Opening curly bracket expected.'.buffer);
    result.pushHead(Tok(tok));
    
    depth := 1;
    while (depth) {
        tok = ctx.getToken();
        if (tok.isEnd())
            ctx.error(tok, 'Premature end of file'.buffer);
        if (tok.isLCurly())
            ++depth;
        else if (tok.isRCurly())
            --depth;
        result.pushHead(Tok(tok));
        if (tok.isIstrBegin())
            readIStr(ctx, result);
    }
    
    return result;
}

void _parseGenericArgs(CrackContext ctx, NodeList tokens) {
    while (true) {
        tok := ctx.getToken();
        if (!tok.isIdent())
            ctx.error(tok, 'Identifier expected in generic definition'.buffer);
        tokens.append(Tok(tok));
        
        tok = ctx.getToken();
        tokens.append(Tok(tok));
        if (tok.isRBracket())
            return;
        else if (!tok.isComma())
            ctx.error(tok, 
                      'Comma or closing bracket expected in generic definition'.
                       buffer
                      );
    }
}

## Writes a NodeList to an output stream separated by whitespace.
class TokenWriter {
    NodeList tokens;
    oper init(NodeList tokens) : tokens = tokens {}
    void writeTo(Writer out) {
        for (tok :in tokens) {
            out.write(tok.toString(null));
            out.write(' ');
        }
    }
}

## An annotation that defines an interface.
void interface(CrackContext ctx) {
    nameTok := ctx.getToken();
    if (!nameTok.isIdent())
        ctx.error(nameTok, 'identifier expected for interface name'.buffer);
    
    # check for generic arguments
    tok := ctx.getToken();
    NodeListImpl genericArgs = {};
    if (tok.isLBracket()) {
        genericArgs.append(Tok(tok));
        _parseGenericArgs(ctx, genericArgs);
    } else {
        ctx.putBack(tok);
    }

    # read the body
    body := readBlock(ctx);
    
    # remove the closing bracket, store the location for error reporting
    loc := body.popHead().getLocation();
    
    # inject the bind, release and get*Object() methods
    StringFormatter f = {};
    f `
    Object get$(nameTok.getText())Object() { return null; }
    @final oper bind() {
        if (!(this is null)) get$(nameTok.getText())Object().oper bind();
    }
    @final oper release() {
        if (!(this is null)) get$(nameTok.getText())Object().oper release(); 
    }
}\0`;
    ctx.inject(loc.getName(), loc.getLineNumber(), f.createString().buffer);

    # expand the body and opening bracket
    for (node :in body)
        node.expand(ctx, null);

    # inject the class definition
    loc = nameTok.getLocation();
    f = StringFormatter();
    f `class $(nameTok.getText())$(TokenWriter(genericArgs)) : VTableBase\n\0`;
    ctx.inject(loc.getName(), loc.getLineNumber(), f.createString().buffer);
}

## An annotation to be used before the list of interfaces that a class 
## implements, e.g.
void implements(CrackContext ctx) {
    # parse the list of interfaces
    NodeListImpl interfaces = {};
    Array[String] ifaces = {4};

    Token firstTok;
    while (true) {
        tok := ctx.getToken();

        if (firstTok is null)
            firstTok = tok;

        if (tok.isLCurly()) {
            ctx.putBack(tok);
            break;
        
        # store identifiers in an array so we can generate the get*Object() 
        # methods.
        } else if (tok.isIdent()) {
            ifaces.append(String(tok.getText()));
        }
        interfaces.pushHead(Tok(tok));
    }

    # add a comma to the end of the list (so it will show up at the beginning 
    # of the list when we expand it)
    interfaces.append(
        Tok(Token(TOK_COMMA, ",".buffer, firstTok.getLocation()))
    );

    
    # read the body.
    body := readBlock(ctx);

    # remove the closing bracket, store the location for error reporting
    loc := body.popHead().getLocation();
    
    # inject the get*Object() implementation
    StringFormatter f = {};
    for (iface :in ifaces)
        f `    Object get$(iface)Object() { return this; }\n`;
    f `}\0`;
    ctx.inject(loc.getName(), loc.getLineNumber(), f.createString().buffer);
    
    # inject the body
    for (node :in body)
        node.expand(ctx, null);
    
    # inject the interfaces
    for (node :in interfaces)
        node.expand(ctx, null);
}

void warn(CrackContext ctx) {
    tok := ctx.getToken();
    if (!tok.isString())
        ctx.error(tok, "String expected after @warn annotation".buffer);
    ctx.warn(tok, tok.getText());
}
